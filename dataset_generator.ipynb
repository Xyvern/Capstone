{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET GENERATOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\darryl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\darryl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\darryl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\darryl\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\darryl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\darryl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\darryl\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Umur (bulan) Jenis Kelamin  Tinggi Badan (cm)       Status Gizi\n",
      "0             0     laki-laki          44.591973           stunted\n",
      "1             0     laki-laki          56.705203            tinggi\n",
      "2             0     laki-laki          46.863358            normal\n",
      "3             0     laki-laki          47.508026            normal\n",
      "4             0     laki-laki          42.743494  severely stunted\n"
     ]
    }
   ],
   "source": [
    "# Nama file yang mau jadi dataset di dalem folder data\n",
    "fileName = 'data_balita.csv'\n",
    "\n",
    "filePath = os.path.join(os.getcwd(), 'data', 'source', fileName)\n",
    "data = pd.read_csv(filePath)\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ganti sama nilai train/total ex. 98% train 2% test diisi 0.98\n",
    "dataSplit = 0.98\n",
    "\n",
    "shuffledIndices = np.random.permutation(len(data))\n",
    "shuffledData = data.iloc[shuffledIndices].reset_index(drop=True)\n",
    "dataSplitIndex = int(0.98 * len(shuffledData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = shuffledData.iloc[:dataSplitIndex]\n",
    "testData = shuffledData.iloc[dataSplitIndex:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Training Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Gizi\n",
      "normal              66427\n",
      "severely stunted    19464\n",
      "tinggi              19142\n",
      "stunted             13546\n",
      "Name: count, dtype: int64\n",
      "Status Gizi\n",
      "normal              13546\n",
      "severely stunted    13546\n",
      "tinggi              13546\n",
      "stunted             13546\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Darryl\\AppData\\Local\\Temp\\ipykernel_16008\\2719725547.py:15: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_train = pd.concat([final_train, pruned_records], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Check label distribution\n",
    "status_count = trainData['Status Gizi'].value_counts()\n",
    "print(status_count)\n",
    "\n",
    "# Create a new empty dataframe\n",
    "columns = ['Umur (bulan)', 'Jenis Kelamin', 'Tinggi Badan (cm)', 'Status Gizi']\n",
    "final_train = pd.DataFrame(columns=columns)\n",
    "\n",
    "# get the min value\n",
    "min_count = status_count.min()\n",
    "\n",
    "# Add record to empty dataframe\n",
    "for status, count in status_count.items():\n",
    "    pruned_records = trainData[trainData['Status Gizi'] == status].head(min_count)\n",
    "    final_train = pd.concat([final_train, pruned_records], ignore_index=True)\n",
    "\n",
    "# Check the final training data composition\n",
    "print(final_train['Status Gizi'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ganti sesuai konteks\n",
    "folderName = \"StuntingClassificationDataset\"\n",
    "\n",
    "outputDir = os.path.join(os.getcwd(), 'data', folderName)\n",
    "os.makedirs(outputDir, exist_ok=True)\n",
    "\n",
    "trainData.to_csv(os.path.join(outputDir, 'train.csv'), index=False)\n",
    "testData.to_csv(os.path.join(outputDir, 'test.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
