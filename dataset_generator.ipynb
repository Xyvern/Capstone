{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET GENERATOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Umur (bulan)</th>\n",
       "      <th>Jenis Kelamin</th>\n",
       "      <th>Tinggi Badan (cm)</th>\n",
       "      <th>Status Gizi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>laki-laki</td>\n",
       "      <td>44.591973</td>\n",
       "      <td>stunted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>laki-laki</td>\n",
       "      <td>56.705203</td>\n",
       "      <td>tinggi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>laki-laki</td>\n",
       "      <td>46.863358</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>laki-laki</td>\n",
       "      <td>47.508026</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>laki-laki</td>\n",
       "      <td>42.743494</td>\n",
       "      <td>severely stunted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Umur (bulan) Jenis Kelamin  Tinggi Badan (cm)       Status Gizi\n",
       "0             0     laki-laki          44.591973           stunted\n",
       "1             0     laki-laki          56.705203            tinggi\n",
       "2             0     laki-laki          46.863358            normal\n",
       "3             0     laki-laki          47.508026            normal\n",
       "4             0     laki-laki          42.743494  severely stunted"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variable\n",
    "fileName = 'data_balita.csv'\n",
    "\n",
    "# Do not change\n",
    "filePath = os.path.join(os.getcwd(), 'data', 'source', fileName)\n",
    "data = pd.read_csv(filePath)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120999, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do not change\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check For NULL Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Umur (bulan)         0\n",
       "Jenis Kelamin        0\n",
       "Tinggi Badan (cm)    0\n",
       "Status Gizi          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do not change\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Records Based On Labels Then Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not change\n",
    "severelyStuntedData = data[data['Status Gizi'] == 'severely stunted']\n",
    "stuntedData = data[data['Status Gizi'] == 'stunted']\n",
    "normalData = data[data['Status Gizi'] == 'normal']\n",
    "tinggiData = data[data['Status Gizi'] == 'tinggi']\n",
    "\n",
    "severelyStuntedData = severelyStuntedData.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "stuntedData = stuntedData.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "normalData = normalData.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "tinggiData = tinggiData.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Each Group To Create Training, Validation, And Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119787, 4) (1212, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Darryl\\AppData\\Local\\Temp\\ipykernel_10456\\1794065103.py:12: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  trainData = pd.concat([trainData, trainSplit], ignore_index=True)\n",
      "C:\\Users\\Darryl\\AppData\\Local\\Temp\\ipykernel_10456\\1794065103.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  valtestData = pd.concat([valtestData, valtestSplit], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Variable\n",
    "dataSplit = 0.99\n",
    "\n",
    "# Do not change\n",
    "columns = ['Umur (bulan)', 'Jenis Kelamin', 'Tinggi Badan (cm)', 'Status Gizi']\n",
    "trainData = pd.DataFrame(columns=columns)\n",
    "valtestData = pd.DataFrame(columns=columns)\n",
    "\n",
    "splitIndex = int(severelyStuntedData.shape[0] * dataSplit)\n",
    "trainSplit = severelyStuntedData[:splitIndex]\n",
    "valtestSplit = severelyStuntedData[splitIndex:]\n",
    "trainData = pd.concat([trainData, trainSplit], ignore_index=True)\n",
    "valtestData = pd.concat([valtestData, valtestSplit], ignore_index=True)\n",
    "\n",
    "splitIndex = int(stuntedData.shape[0] * dataSplit)\n",
    "trainSplit = stuntedData[:splitIndex]\n",
    "valtestSplit = stuntedData[splitIndex:]\n",
    "trainData = pd.concat([trainData, trainSplit], ignore_index=True)\n",
    "valtestData = pd.concat([valtestData, valtestSplit], ignore_index=True)\n",
    "\n",
    "splitIndex = int(normalData.shape[0] * dataSplit)\n",
    "trainSplit = normalData[:splitIndex]\n",
    "valtestSplit = normalData[splitIndex:]\n",
    "trainData = pd.concat([trainData, trainSplit], ignore_index=True)\n",
    "valtestData = pd.concat([valtestData, valtestSplit], ignore_index=True)\n",
    "\n",
    "splitIndex = int(tinggiData.shape[0] * dataSplit)\n",
    "trainSplit = tinggiData[:splitIndex]\n",
    "valtestSplit = tinggiData[splitIndex:]\n",
    "trainData = pd.concat([trainData, trainSplit], ignore_index=True)\n",
    "valtestData = pd.concat([valtestData, valtestSplit], ignore_index=True)\n",
    "\n",
    "print(trainData.shape,valtestData.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Trainingset Distribution And Prune To Get Equally Distributed Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Gizi\n",
      "normal              67077\n",
      "severely stunted    19670\n",
      "tinggi              19364\n",
      "stunted             13676\n",
      "Name: count, dtype: int64\n",
      "Status Gizi\n",
      "normal              13676\n",
      "severely stunted    13676\n",
      "tinggi              13676\n",
      "stunted             13676\n",
      "Name: count, dtype: int64\n",
      "(54704, 4) (66295, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Darryl\\AppData\\Local\\Temp\\ipykernel_10456\\807327390.py:12: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  finalTrain = pd.concat([finalTrain, keepedRecords], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Do not change\n",
    "statusCount = trainData['Status Gizi'].value_counts()\n",
    "print(statusCount)\n",
    "\n",
    "finalTrain = pd.DataFrame(columns=columns)\n",
    "\n",
    "minCount = statusCount.min()\n",
    "for status, count in statusCount.items():\n",
    "    prunedRecords = trainData[trainData['Status Gizi'] == status][minCount:]\n",
    "    keepedRecords = trainData[trainData['Status Gizi'] == status][:minCount]\n",
    "    valtestData = pd.concat([valtestData, prunedRecords], ignore_index=True)\n",
    "    finalTrain = pd.concat([finalTrain, keepedRecords], ignore_index=True)\n",
    "\n",
    "statusCount = finalTrain['Status Gizi'].value_counts()\n",
    "print(statusCount)\n",
    "print(finalTrain.shape,valtestData.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split ValtestData Into Validationset and Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54704, 4) (65632, 4) (663, 4)\n"
     ]
    }
   ],
   "source": [
    "# Variable\n",
    "split = 0.99\n",
    "# Do not change\n",
    "splitIndex = int(valtestData.shape[0] * split)\n",
    "valtestData = valtestData.sample(frac=1, random_state=50).reset_index(drop=True)\n",
    "\n",
    "finalVal = valtestData.iloc[:splitIndex]\n",
    "finalTest = valtestData.iloc[splitIndex:]\n",
    "\n",
    "print(finalTrain.shape,finalVal.shape,finalTest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save The Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable\n",
    "folderName = \"StuntingClassificationDataset\"\n",
    "\n",
    "# Do not change\n",
    "outputDir = os.path.join(os.getcwd(), 'data', folderName)\n",
    "os.makedirs(outputDir, exist_ok=True)\n",
    "\n",
    "finalTrain.to_csv(os.path.join(outputDir, 'train.csv'), index=False)\n",
    "finalVal.to_csv(os.path.join(outputDir, 'val.csv'), index=False)\n",
    "finalTest.to_csv(os.path.join(outputDir, 'test.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
